{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 15:22:37.147443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ascii text and convert it to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mapping of unique chars to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] \n",
      "\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, '@': 28, '[': 29, ']': 30, '_': 31, 'a': 32, 'b': 33, 'c': 34, 'd': 35, 'e': 36, 'f': 37, 'g': 38, 'h': 39, 'i': 40, 'j': 41, 'k': 42, 'l': 43, 'm': 44, 'n': 45, 'o': 46, 'p': 47, 'q': 48, 'r': 49, 's': 50, 't': 51, 'u': 52, 'v': 53, 'w': 54, 'x': 55, 'y': 56, 'z': 57}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars,\"\\n\")\n",
    "\n",
    "# give an integer to each character, index in the list as the integer value for character\n",
    "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the details of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Characters:  163780\n",
      "Total Vocab(Unique characters):  58\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total number of Characters: \", n_chars)\n",
    "print(\"Total Vocab(Unique characters): \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset of input to output pairs encoded as integers\n",
    "<br>\n",
    "select 100 letters at a time and count the number of 100 letter blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  163680\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100 # can be changed\n",
    "dataX = []\n",
    "dataY = [] \n",
    "for i in range(0,n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataY)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 46, 41, 36, 34, 51, 1, 38, 52, 51, 36, 45, 33, 36, 49, 38, 7, 50, 1, 32, 43, 40, 34, 36, 7, 50, 1, 32, 35, 53, 36, 45, 51, 52, 49, 36, 50, 1, 40, 45, 1, 54, 46, 45, 35, 36, 49, 43, 32, 45, 35, 11, 1, 33, 56, 1, 43, 36, 54, 40, 50, 1, 34, 32, 49, 49, 46, 43, 43, 0, 0, 51, 39, 40, 50, 1, 36, 33, 46, 46, 42, 1, 40, 50, 1, 37, 46, 49, 1, 51, 39, 36, 1, 52, 50, 36, 1, 46, 37, 1]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# second 100 character block (starting from r)\n",
    "print(dataX[1])\n",
    "# what character will come after that 100 character block\n",
    "print(dataY[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform input sequences into form expected by LSTM network & Rescale integers to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.81034483]\n",
      "  [0.84482759]\n",
      "  [0.79310345]\n",
      "  ...\n",
      "  [0.01724138]\n",
      "  [0.79310345]\n",
      "  [0.63793103]]\n",
      "\n",
      " [[0.84482759]\n",
      "  [0.79310345]\n",
      "  [0.70689655]\n",
      "  ...\n",
      "  [0.79310345]\n",
      "  [0.63793103]\n",
      "  [0.01724138]]\n",
      "\n",
      " [[0.79310345]\n",
      "  [0.70689655]\n",
      "  [0.62068966]\n",
      "  ...\n",
      "  [0.63793103]\n",
      "  [0.01724138]\n",
      "  [0.55172414]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.87931034]\n",
      "  [0.79310345]\n",
      "  [0.01724138]\n",
      "  ...\n",
      "  [0.79310345]\n",
      "  [0.79310345]\n",
      "  [0.72413793]]\n",
      "\n",
      " [[0.79310345]\n",
      "  [0.01724138]\n",
      "  [0.67241379]\n",
      "  ...\n",
      "  [0.79310345]\n",
      "  [0.72413793]\n",
      "  [0.86206897]]\n",
      "\n",
      " [[0.01724138]\n",
      "  [0.67241379]\n",
      "  [0.62068966]\n",
      "  ...\n",
      "  [0.72413793]\n",
      "  [0.86206897]\n",
      "  [0.22413793]]]\n"
     ]
    }
   ],
   "source": [
    "# reshape x to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize - rescaling the integer values\n",
    "X = X / float(n_vocab)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert output values (single characters converted to integers) to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 15:22:52.673595: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# it can have one or more training samples\n",
    "model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2])))\n",
    "# can reduce complexity by adding dropout\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam')\n",
    "\n",
    "# define the checkpoint\n",
    "filepath = 'weights-improvement-{epoch:02d}-{loss:.4f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath = filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.9723\n",
      "Epoch 1: loss improved from inf to 2.97230, saving model to weights-improvement-01-2.9723.hdf5\n",
      "1279/1279 [==============================] - 413s 322ms/step - loss: 2.9723\n",
      "Epoch 2/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.8009\n",
      "Epoch 2: loss improved from 2.97230 to 2.80086, saving model to weights-improvement-02-2.8009.hdf5\n",
      "1279/1279 [==============================] - 461s 360ms/step - loss: 2.8009\n",
      "Epoch 3/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.7153\n",
      "Epoch 3: loss improved from 2.80086 to 2.71533, saving model to weights-improvement-03-2.7153.hdf5\n",
      "1279/1279 [==============================] - 512s 400ms/step - loss: 2.7153\n",
      "Epoch 4/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.6449\n",
      "Epoch 4: loss improved from 2.71533 to 2.64485, saving model to weights-improvement-04-2.6449.hdf5\n",
      "1279/1279 [==============================] - 674s 527ms/step - loss: 2.6449\n",
      "Epoch 5/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.5927\n",
      "Epoch 5: loss improved from 2.64485 to 2.59266, saving model to weights-improvement-05-2.5927.hdf5\n",
      "1279/1279 [==============================] - 653s 511ms/step - loss: 2.5927\n",
      "Epoch 6/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.5377\n",
      "Epoch 6: loss improved from 2.59266 to 2.53773, saving model to weights-improvement-06-2.5377.hdf5\n",
      "1279/1279 [==============================] - 343s 268ms/step - loss: 2.5377\n",
      "Epoch 7/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.4870\n",
      "Epoch 7: loss improved from 2.53773 to 2.48698, saving model to weights-improvement-07-2.4870.hdf5\n",
      "1279/1279 [==============================] - 383s 300ms/step - loss: 2.4870\n",
      "Epoch 8/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.4402\n",
      "Epoch 8: loss improved from 2.48698 to 2.44015, saving model to weights-improvement-08-2.4402.hdf5\n",
      "1279/1279 [==============================] - 463s 362ms/step - loss: 2.4402\n",
      "Epoch 9/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.3998\n",
      "Epoch 9: loss improved from 2.44015 to 2.39981, saving model to weights-improvement-09-2.3998.hdf5\n",
      "1279/1279 [==============================] - 426s 333ms/step - loss: 2.3998\n",
      "Epoch 10/10\n",
      "1279/1279 [==============================] - ETA: 0s - loss: 2.3613\n",
      "Epoch 10: loss improved from 2.39981 to 2.36129, saving model to weights-improvement-10-2.3613.hdf5\n",
      "1279/1279 [==============================] - 419s 327ms/step - loss: 2.3613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14436ea10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the hyperparameter values and train model\n",
    "# when no.of epochs increases model can be trainable well and loss will decrease \n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "model.fit(X, y, epochs = epochs, batch_size = batch_size, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text with the trained LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weight with lowest loss\n",
    "filename = \"weights-improvement-10-2.4187.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mapping of unique integers to chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163680\n",
      "53033\n",
      "Seed:\n",
      "\"  said to herself, and nibbled a little of\n",
      "the right-hand bit to try the effect: the next moment she  \"\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "start = np.random.randint(0, len(dataX) - 1)\n",
    "print(start)\n",
    "# dataX contains list of patterns\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', 'o', 'r', 'k', 'e', ' ', 't', 'h', ' ', 't', 'h', 'e', ' ', 'w', 'o', 'r', 'k', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "# generate next 100 characters\n",
    "length = 100\n",
    "final = []\n",
    "\n",
    "for i in range(length):\n",
    "    # reshaping the seed sequence before passing it to the LSTM model\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    # print(x)\n",
    "    # normalize the integer values\n",
    "    x = x / float(n_vocab)\n",
    "    # print(x)\n",
    "    # making the predictions\n",
    "    prediction = model.predict(x, verbose = 0)\n",
    "    # get the predicted value with maximum probability\n",
    "    index = np.argmax(prediction)\n",
    "\n",
    "    # convert the predicted integer values to char\n",
    "    result = int_to_char[index]\n",
    "    # print(result)\n",
    "    final.append(result)\n",
    "    # adding the predicted character to the sequence\n",
    "    pattern.append(index)\n",
    "    # removing the first character from the seed sequence\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
